\section{Markov Chain Mixing to Distinguish Money States}

In Step 4 of the verification scheme, we apply a Markov chain
$\hat{B}$ and then
project onto its +1 eigenstates. This depends on valid money states
$\ket{\$_p}$
being very close to +1 eigenstates of $\hat{B}$, much closer than
the eigenstates corresponding to invalid money. 
Valid money states cannot be exactly +1 eigenstates, because those
include mixing from grid diagrams in $\mathcal{G}$ above,
with size in the tails that we cut off in Step 3. Therefore, our only
hope is that the eigenvalues for $\ket{\$_p}$ being exponentially
close to one and the eigenvalues for all other states being at least
polynomially farther away.

Unfortunately, we don't understanding enough about knots to make that
claim for this particular Markov chain. This is the biggest open
question and avenue for attack in our knot-based scheme.
In particular, we don't know
the eigenvalue gap, if any, between the lowest eigenvalue of
a $\ket{\$_p}$ (call it $(1-a), a \in [0,1)$) and the highest eigenvalue of any other
eigenstates (call it $(1-b), b \in [0,1)$). We are guaranteed to be exponentially close
to some eigenstate of $\hat{B}$ after calculating and measuring the
Alexander polynomial in Step 2 above.

However, as dreamers, we can imagine what desirable properties we would
like to prove for $\hat{B}$. First, we would like $b > a$, so that
there is a gap. First, we would like to show that $a$ is
small, so a $\ket{\$_p}$ doesn't degrade under
$r$ repetitions of Markov chain verification and still projects
to a +1 eigenstate with high probability.

\begin{displaymath}
a = \frac{1}{\exp(\Omega(\overline{D}))}
\end{displaymath}

Second, we would like to show that $b$ is polynomially away from 1, so
that under $r$ repetitions of Markov chain verification, it
projects to a +1 eigenstate with low probability.

\begin{displaymath}
b = \frac{1}{\Omega(\overline{D})}
\end{displaymath}

We would like to show that difference in probabilities increases
exponentially close to 1 with $r$:

\begin{multline*}
(1-a)^r - (1-b)^r \ge (1 - ra) - (1 - rb) \\
= r(b-a) =
\frac{1}{\exp(\Omega(\overline{D}))} - \frac{1}{\Omega(\overline{D})}
\end{multline*}

Therefore, if $(b-a)$ also increases exponentially closer to 1, we can
get away with $r = \textrm{poly}(\overline{D})$ repetitions, so that our
Markov chain verification procedure is tractable.